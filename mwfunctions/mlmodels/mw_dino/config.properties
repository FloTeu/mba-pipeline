inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
service_envelope=json
install_py_dep_per_model=true

# Can be used to debug on cpu
# number_of_gpu=1

# Maybe works in future torchserve==0.4.1
# load_models=dino_xcit_small_12_p16.mar
# models={"dino_vitb8": {"1.0": {"defaultVersion": true,"marName": "dino_vitb8.mar","minWorkers": 1,"maxWorkers": 1,"batchSize": 3,"maxBatchDelay": 5000,"responseTimeout": 120}}}

# models={\
#   "dino_xcit_small_12_p16": {\
#     "1.0": {\
#         "defaultVersion": true,\
#         "marName": "dino_xcit_small_12_p16.mar",\
#         "minWorkers": 1,\
#         "maxWorkers": 1,\
#         "batchSize": 128,\
#         "maxBatchDelay": 1000,\
#         "responseTimeout": 120\
#     }\
#   },\
# }
